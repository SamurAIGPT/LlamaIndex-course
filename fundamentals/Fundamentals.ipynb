{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamurAIGPT/LlamaIndex-course/blob/main/fundamentals/Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKiW9QLJdYzI"
      },
      "source": [
        "# LlamaIndex fundamentals\n",
        "\n",
        "In this lesson we discuss the fundamentals of LlamaIndex and it's core components\n",
        "\n",
        "We will be discussing the below in this lesson\n",
        "\n",
        "1. Nodes\n",
        "2. Document loaders\n",
        "3. Indexes\n",
        "4. Retrievers\n",
        "5. Query Engines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXfewCv1eq4t"
      },
      "source": [
        "### Nodes\n",
        "\n",
        "Node is the fundamental unit of LlamaIndex. Node is nothing but a data structure which contains a piece of text.\n",
        "\n",
        "Whenever you are provided a document, you can split into multiple chunks and store in nodes\n",
        "\n",
        "### Document Loader\n",
        "\n",
        "Document Loader in LlamaIndex is an interface to extract data from a source. The source can be a webpage, youtube video, pdf etc.\n",
        "\n",
        "LlamaIndex supports a bunch of document loaders and we will be studying some of them for our usecase\n",
        "\n",
        "### Indexes\n",
        "\n",
        "An index in LlamaIndex is a data structure that organizes and stores information from various data sources, making it easier to search. An index is built over a bunch of nodes\n",
        "\n",
        "LlamaIndex offers different types of indices which we will be studying in further lessons\n",
        "\n",
        "### Retrievers\n",
        "\n",
        "A retriever in LlamaIndex helps fetch a set of Nodes from an index based on a given query. It's like a search tool that finds relevant information from a large dataset to answer your question.\n",
        "\n",
        "There are different types of retrievers in LlamaIndex which we will be studying in further lessons\n",
        "\n",
        "### Query Engines\n",
        "\n",
        "A query engine in LlamaIndex processes user input query, interacts with the underlying data structures (like indexes), and returns a synthesized response.\n",
        "\n",
        "LlamaIndex offers different types of query engines which we will be studying in further lessons\n",
        "\n",
        "Let's try to understand all these concepts with the help of an example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkTzHRzAj-a4"
      },
      "source": [
        "### Install LlamaIndex and dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGjuOcztdVdY"
      },
      "outputs": [],
      "source": [
        "!pip install llama_index langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7brjnBgakDxt"
      },
      "source": [
        "### Download the data to train on. We use state of the union text document to train over ChatGPT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N19pdxXakBf_"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt\n",
        "!mkdir data\n",
        "!mv state_of_the_union.txt data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q1uZIhJkSCi"
      },
      "source": [
        "### Load the input text into LlamaIndex input. We can do this using a simple Document loader which we discussed above.\n",
        "\n",
        "We will be using SimpleDirectoryReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"api-key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wjCCvXkxkJjO"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader('./data').load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoOwPvXrkrZ9"
      },
      "source": [
        "### Split the data into nodes.\n",
        "\n",
        "As we discussed Node is the fundamental data structure which holds the input. We will take the above loaded input and split into multiple nodes using the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VSd_W7FXkmvi"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "parser = SimpleNodeParser()\n",
        "nodes = parser.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81GvDT90lHrZ"
      },
      "source": [
        "### Create an Index\n",
        "\n",
        "Now that we have the nodes created, we can create an index on top of it. We will be using VectorStoreIndex which creates embeddings from all the text in the nodes and store it in a vector db. More details on embeddings are shared in the first lesson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qV8KYogxlD2I"
      },
      "outputs": [],
      "source": [
        "from llama_index import LLMPredictor, VectorStoreIndex\n",
        "from langchain import OpenAI\n",
        "\n",
        "\n",
        "index = VectorStoreIndex(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jxcV3s5oZGf"
      },
      "source": [
        "### Create a retriever\n",
        "\n",
        "We will be using VectorIndexRetriever which retrieves the top k matching documents based on similarity. For this example we will keep k=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WTHjqs8pmbKm"
      },
      "outputs": [],
      "source": [
        "from llama_index.retrievers import VectorIndexRetriever\n",
        "\n",
        "retriever = VectorIndexRetriever(\n",
        "    index=index,\n",
        "    similarity_top_k=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G44xOu2pop2e"
      },
      "source": [
        "### Create a query engine\n",
        "\n",
        "Now we can construct a query engine over our retriever to start making queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rsXYrMTTosPT"
      },
      "outputs": [],
      "source": [
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuZNWum3o5Rz"
      },
      "source": [
        "### Now make a query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzA8F5d1o7Ss",
        "outputId": "4fe4fc93-e62b-4b73-c52b-6fc5e93496d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The author grew up in a family where they had to adjust to the rising cost of food, gas, housing, and other expenses. They experienced the struggles of their father leaving home to find work.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP4BaEr/v1gFjHe9TUouSak",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
